#!/usr/bin/env python3
"""
ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ë‹¤ì¤‘ ë¡œê·¸ ìƒì„±ê¸° - ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ (í•™ìŠµ ê¸°ëŠ¥ í†µí•©)
"""

import streamlit as st
import os
from datetime import datetime
from dotenv import load_dotenv

# --- ê¸°ì¡´ ëª¨ë“ˆ ---
from src.nlp_processor import NLPProcessor
from src.scenario_manager import ScenarioManager
from src.log_generator import LogGenerator
from src.download_manager import DownloadManager
from src.query_optimizer_service import QueryOptimizerService
# --- ê¸°ëŠ¥ ì¶”ê°€ë¥¼ ìœ„í•´ ìƒˆë¡œ ì„í¬íŠ¸ ---
from src.case_library_manager import CaseLibraryManager
from src.progress_manager import ProgressManager

import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from back.explain import explain_spl_markdown_backend

def main():
    st.set_page_config(
        page_title="SPLearn",
        page_icon="ğŸš€",
        layout="wide"
    )
    
    # --- ì‚¬ì´ë“œë°” UI (ì‚¬ìš©ì ì´ë¦„ ì…ë ¥ ì¶”ê°€) ---
    with st.sidebar:
        st.header("ğŸ‘¤ ì‚¬ìš©ì")
        user_id = st.text_input("ì‚¬ìš©ì ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="í•™ìŠµ ê¸°ë¡ì„ ìœ„í•´ ì´ë¦„ ì…ë ¥")

        st.divider()
        st.header("ğŸ”‘ ì„¤ì •")
        load_dotenv()
        api_key = os.getenv('OPENAI_API_KEY', '')
        
        if api_key:
            st.success("âœ… API í‚¤ ì„¤ì •ë¨")
        else:
            st.warning("âš ï¸ .env íŒŒì¼ì— API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        
        st.divider()
        st.header("ğŸ“Š ìƒì„± ì„¤ì •")
        log_count = st.number_input("ë¡œê·¸ ê°œìˆ˜ (íŒŒì¼ë‹¹)", min_value=100, max_value=10000, value=1000, step=100)
    
    # --- ë©”ì¸ í—¤ë” (ê¸°ì¡´ê³¼ ë™ì¼) ---
    st.title("ğŸš€ SPLearn")
    st.markdown("**SPLunkì˜ í•™ìŠµì„ ë•ìŠµë‹ˆë‹¤.**")
    
    # --- í•„ìˆ˜ ì…ë ¥ê°’ ê²€ì¦ ---
    if not api_key:
        st.error("ë¨¼ì € .env íŒŒì¼ì— OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return
    if not user_id:
        st.info("ì‚¬ì´ë“œë°”ì— ì‚¬ìš©ì ì´ë¦„ì„ ì…ë ¥í•˜ë©´ í•™ìŠµ ê¸°ëŠ¥ì´ í™œì„±í™”ë©ë‹ˆë‹¤.")
        return
    
    # --- ì‚¬ìš©ì ë³€ê²½ ê°ì§€ ë° ì„¸ì…˜ ì´ˆê¸°í™” ë¡œì§ ---
    if 'current_user_id' not in st.session_state:
        st.session_state['current_user_id'] = user_id

    if st.session_state['current_user_id'] != user_id:
        # ì‚¬ìš©ìê°€ ë³€ê²½ë˜ì—ˆìœ¼ë¯€ë¡œ, ì´ì „ ì‚¬ìš©ìì˜ ì‘ì—… ë‚´ìš©ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        keys_to_clear = ['processed_scenario', 'generated_logs', 'optimized_spl']
        for key in keys_to_clear:
            if key in st.session_state:
                del st.session_state[key]
        # í˜„ì¬ ì‚¬ìš©ìë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  í™”ë©´ì„ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ì´ˆê¸°í™”ëœ ìƒíƒœë¥¼ ì¦‰ì‹œ ë°˜ì˜í•©ë‹ˆë‹¤.
        st.session_state['current_user_id'] = user_id
        st.rerun()
    
    # --- ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” (ì‚¬ìš©ìë³„ ê´€ë¦¬ì ì¶”ê°€) ---
    progress_manager = ProgressManager()
    case_library_manager = CaseLibraryManager(user_id=user_id)
    nlp_processor = NLPProcessor(api_key)
    scenario_manager = ScenarioManager()
    log_generator = LogGenerator()
    download_manager = DownloadManager()
    query_processor = QueryOptimizerService(api_key, model=os.getenv("OPENAI_MODEL", "gpt-4.1"))
    
    # --- íƒ­ êµ¬ì„± (ìˆœì„œ ë³€ê²½) ---
    tab_list = [
        "ğŸ“ ì‹œë‚˜ë¦¬ì˜¤ ì…ë ¥", "ğŸ“¥ ìƒì„±ëœ ë¡œê·¸", "ğŸ” Splunk Query ìƒì„±",
        "ğŸ“Š í•™ìŠµ ëŒ€ì‹œë³´ë“œ", "ğŸ“‹ ìƒ˜í”Œ ì‹œë‚˜ë¦¬ì˜¤", "ğŸ—‚ï¸ ì¼€ì´ìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬"
    ]
    tab_input, tab_logs, tab_query, tab_dashboard, tab_samples, tab_library = st.tabs(tab_list)

    # --- í•™ìŠµ ëŒ€ì‹œë³´ë“œ íƒ­ êµ¬í˜„ ---
    with tab_dashboard:
        st.header(f"ğŸ“Š {user_id}ë‹˜ì˜ í•™ìŠµ ëŒ€ì‹œë³´ë“œ")
        all_scenarios = list(scenario_manager.get_sample_scenarios().values()) + case_library_manager.load_cases()
        stats = progress_manager.get_dashboard_stats(user_id, all_scenarios)

        col1, col2, col3 = st.columns(3)
        col1.metric("ì´ ì‹œë‚˜ë¦¬ì˜¤", f"{stats['total_count']}ê°œ")
        col2.metric("ì™„ë£Œ", f"{stats['completed_count']}ê°œ")
        col3.metric("ë‹¬ì„±ë¥ ", f"{stats['completion_rate']:.1%}")
        st.progress(stats['completion_rate'])
        
        st.subheader("ë‚œì´ë„ë³„ ì§„í–‰ë„")
        stats_by_difficulty = stats['stats_by_difficulty']
        cols = st.columns(len(stats_by_difficulty))
        for i, (diff, data) in enumerate(stats_by_difficulty.items()):
            with cols[i]:
                st.markdown(f"**{diff}**")
                rate = data['completed'] / data['total'] if data['total'] > 0 else 0
                st.progress(rate, text=f"{data['completed']} / {data['total']}ê°œ")

    # --- ì‹œë‚˜ë¦¬ì˜¤ ì…ë ¥ íƒ­ (ê¸°ì¡´ê³¼ ë™ì¼) ---
    with tab_input:
        st.header("ğŸ“ ìì—°ì–´ ì‹œë‚˜ë¦¬ì˜¤ ì…ë ¥")
        scenario_input = st.text_area(
            "ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìì—°ì–´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            placeholder="ì˜ˆ: ì›¹ì„œë²„ì— ëŒ€í•œ ì™¸ë¶€ ì¹¨ì… ê³µê²© ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. ê³µê²©ìê°€ SQL ì¸ì ì…˜ì„ í†µí•´ ê´€ë¦¬ì ê³„ì •ì„ íƒˆì·¨í•˜ê³  ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê³ ê° ì •ë³´ë¥¼ ë¹¼ë‚´ëŠ” ìƒí™©ì…ë‹ˆë‹¤.",
            height=150
        )
        col1, col2, col3 = st.columns([1, 1, 1])
        with col1:
            if st.button("ğŸ”„ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ë° êµ¬ì²´í™”", type="primary", use_container_width=True):
                if scenario_input.strip():
                    with st.spinner("AIê°€ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë¶„ì„í•˜ê³  êµ¬ì²´í™”í•˜ëŠ” ì¤‘..."):
                        try:
                            processed_scenario = nlp_processor.process_scenario(scenario_input)
                            st.session_state['processed_scenario'] = processed_scenario
                            st.success("âœ… ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ì™„ë£Œ!")
                        except Exception as e:
                            st.error(f"âŒ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
                else:
                    st.warning("ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        with col2:
            if st.button("ğŸš€ ë¡œê·¸ ìƒì„±", type="secondary", use_container_width=True):
                if 'processed_scenario' in st.session_state:
                    # generate_logs í•¨ìˆ˜ í˜¸ì¶œì— user_idì™€ progress_manager ì¶”ê°€
                    generate_logs(st.session_state['processed_scenario'], log_generator, log_count, user_id, progress_manager)
                else:
                    st.warning("ë¨¼ì € ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.")
        
        with col3:
            if st.button("ğŸ” SPL ë£° ê²€ì¦", type="secondary", use_container_width=True):
                if "optimized_spl" not in st.session_state:
                    st.warning("ë¨¼ì € Splunk ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”. (íƒ­4ì—ì„œ 'ğŸ§  ì¿¼ë¦¬ ìƒì„±/ìµœì í™”' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”)")
                else:
                    with st.spinner("AIê°€ SPL ë£°ì„ ê²€ì¦í•˜ëŠ” ì¤‘..."):
                        try:
                            spl_query = st.session_state["optimized_spl"]
                            spl_result = explain_spl_markdown_backend(spl_query)
                            st.session_state['spl_result'] = spl_result
                            st.success("âœ… SPL ë£° ê²€ì¦ ì™„ë£Œ!")
                        except Exception as e:
                            st.error(f"âŒ SPL ë£° ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
        
        if 'processed_scenario' in st.session_state:
            display_processed_scenario(st.session_state['processed_scenario'])
    
        import re
        if 'spl_result' in st.session_state:
            st.subheader("ğŸ“œ ìƒì„±ëœ SPL ë£° ë° ê²€ì¦ ê²°ê³¼")

            clean_result = st.session_state['spl_result']
            clean_result = re.sub(r"<!--.*?-->", "", clean_result, flags=re.DOTALL).strip()

            st.markdown(
                f"""
                <div style='max-height:400px; overflow-y:auto;
                            background-color:#f8f9fa; padding:15px;
                            border-radius:5px; font-size:15px;'>
                """,
                unsafe_allow_html=True
            )
            st.markdown(clean_result)
            st.markdown("</div>", unsafe_allow_html=True)

    # --- ìƒ˜í”Œ ì‹œë‚˜ë¦¬ì˜¤ íƒ­ (st.rerun() ì¶”ê°€í•˜ì—¬ ì¦‰ì‹œ ë°˜ì‘í•˜ë„ë¡ ìˆ˜ì •) ---
    with tab_samples:
        st.header("ğŸ“‹ ìƒ˜í”Œ ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ")
        samples = scenario_manager.get_sample_scenarios()
        
        scenarios_by_difficulty = {"ì´ˆê¸‰": [], "ì¤‘ê¸‰": [], "ê³ ê¸‰": []}
        for scenario in samples.values():
            scenarios_by_difficulty[scenario.get("difficulty", "ì¤‘ê¸‰")].append(scenario)

        for difficulty, scenarios in scenarios_by_difficulty.items():
            if scenarios:
                with st.expander(f"**{difficulty} ì‹œë‚˜ë¦¬ì˜¤ ({len(scenarios)}ê°œ)**", expanded=(difficulty=="ì´ˆê¸‰")):
                    for scenario in scenarios:
                        if st.button(f"{scenario['title']}", key=f"sample_{scenario['id']}", use_container_width=True):
                            st.session_state['processed_scenario'] = scenario
                            st.rerun()

    # --- ì¼€ì´ìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ íƒ­ (st.rerun() ì¶”ê°€í•˜ì—¬ ì¦‰ì‹œ ë°˜ì‘í•˜ë„ë¡ ìˆ˜ì •) ---
    with tab_library:
        st.header("ğŸ—‚ï¸ ì¼€ì´ìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬")
        cases = case_library_manager.load_cases()
        if not cases:
            st.info("ì €ì¥ëœ ì¼€ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. 'ìƒì„±ëœ ë¡œê·¸' íƒ­ì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì €ì¥í•´ë³´ì„¸ìš”.")
        else:
            for case in cases:
                if st.button(f"{case.get('title')} (ë‚œì´ë„: {case.get('difficulty', 'ë¯¸ì§€ì •')})", key=f"library_{case.get('id')}", use_container_width=True):
                    st.session_state['processed_scenario'] = case
                    st.rerun()

    # --- ìƒì„±ëœ ë¡œê·¸ íƒ­ (ë¼ì´ë¸ŒëŸ¬ë¦¬ ì €ì¥ ë²„íŠ¼ ì¶”ê°€) ---
    with tab_logs:
        st.header("ğŸ“¥ ìƒì„±ëœ ë¡œê·¸ íŒŒì¼")
        if 'generated_logs' in st.session_state:
            if st.button("ğŸ—‚ï¸ ì´ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì¼€ì´ìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì €ì¥", use_container_width=True):
                if case_library_manager.add_case(st.session_state.get('processed_scenario')):
                    st.success("âœ… ì¼€ì´ìŠ¤ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun() 
                else:
                    st.warning("âš ï¸ ì´ë¯¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì¡´ì¬í•˜ëŠ” ì¼€ì´ìŠ¤ì…ë‹ˆë‹¤.")
            display_generated_logs(st.session_state['generated_logs'], download_manager)
        else:
            st.info("ì•„ì§ ìƒì„±ëœ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì„¤ì •í•˜ê³  ë¡œê·¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")

    # --- Splunk Query ìƒì„± íƒ­ (ê¸°ì¡´ê³¼ ë™ì¼) ---
    with tab_query:
        st.header("ğŸ“¥ Splunk Query ìƒì„±")
        st.markdown("---")
        st.subheader("ğŸ” LLM ê¸°ë°˜ Splunk ì¿¼ë¦¬ ìƒì„±")
        def _flatten_scenario_text(scn):
            if isinstance(scn, dict):
                parts = []
                if scn.get("title"): parts.append(str(scn["title"]))
                if scn.get("description"): parts.append(str(scn["description"]))
                if scn.get("timeline"): parts.append("\n".join(map(str, scn["timeline"])))
                return "\n".join(parts).strip()
            return (str(scn) if scn is not None else "").strip()

        if st.button("ğŸ§  ì¿¼ë¦¬ ìƒì„±/ìµœì í™”", use_container_width=True):
            processed_scn  = st.session_state.get("processed_scenario")
            generated_logs = st.session_state.get("generated_logs")
            if not processed_scn:
                st.warning("ì‹œë‚˜ë¦¬ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤. íƒ­ 1ì—ì„œ ë¨¼ì € ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
            else:
                scenario_text = _flatten_scenario_text(processed_scn)
                try:
                    res = query_processor.make_spl(scenario_text=scenario_text, generated_logs=generated_logs)
                    spl = (res.get("query") or "").strip()
                    if not spl: st.error("LLMì´ ë¹ˆ ì¿¼ë¦¬ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.session_state["optimized_spl"] = spl
                        st.success("âœ… ìµœì í™”ëœ ì¿¼ë¦¬ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
                except Exception as e:
                    st.error(f"ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨: {e}")
        
        if "optimized_spl" in st.session_state:
            spl = st.session_state["optimized_spl"]
            st.code(spl, language="spl")
            st.download_button("optimized.spl ë‹¤ìš´ë¡œë“œ", data=spl + "\n", file_name="optimized.spl", mime="text/plain", use_container_width=True)
        else:
            st.info("ì™¼ìª½ ë²„íŠ¼ìœ¼ë¡œ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ë©´ ì—¬ê¸° í‘œì‹œë©ë‹ˆë‹¤.")

# --- í—¬í¼ í•¨ìˆ˜ë“¤ (generate_logs í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ ë³€ê²½) ---

def display_processed_scenario(scenario):
    st.subheader("ğŸ” ë¶„ì„ëœ ì‹œë‚˜ë¦¬ì˜¤")
    with st.container():
        col1, col2 = st.columns([1, 1])
        with col1:
            st.markdown("#### ğŸ“… ê³µê²© íƒ€ì„ë¼ì¸")
            for i, step in enumerate(scenario['timeline'], 1): st.markdown(f"{i}. {step}")
        with col2:
            st.markdown("#### ğŸ“Š ìƒì„±ë  ë¡œê·¸ ì¢…ë¥˜")
            for log_type in scenario['log_types']: st.markdown(f"**{log_type['name']}**: {log_type['description']}")

def generate_logs(scenario, log_generator, log_count, user_id, progress_manager):
    with st.spinner("ë¡œê·¸ íŒŒì¼ë“¤ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
        try:
            progress_bar = st.progress(0)
            status_text = st.empty()
            generated_logs = {}
            total_logs = len(scenario['log_types'])
            for idx, log_type in enumerate(scenario['log_types']):
                status_text.text(f"ìƒì„± ì¤‘: {log_type['name']} ({idx + 1}/{total_logs})")
                log_content = log_generator.generate_log_content(log_type, log_count, scenario)
                generated_logs[log_type['type']] = {
                    'name': log_type['name'], 'content': log_content,
                    'filename': f"{log_type['type']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
                }
                progress = (idx + 1) / total_logs
                progress_bar.progress(progress)
            
            st.session_state['generated_logs'] = generated_logs
            status_text.text("âœ… ëª¨ë“  ë¡œê·¸ ìƒì„± ì™„ë£Œ!")
            
            # ì§„í–‰ë„ ê¸°ë¡ ë° ìƒˆë¡œê³ ì¹¨
            scenario_id = scenario.get('id')
            if scenario_id:
                progress_manager.mark_scenario_completed(user_id, scenario_id)
                st.success(f"ğŸ‰ ë¡œê·¸ ìƒì„± ì™„ë£Œ! í•™ìŠµ ì§„í–‰ë„ì— ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
                st.rerun()
            else:
                st.success(f"ğŸ‰ {total_logs}ê°œì˜ ë¡œê·¸ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        except Exception as e:
            st.error(f"âŒ ë¡œê·¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")

def display_generated_logs(generated_logs, download_manager):
    st.markdown(f"**ì´ {len(generated_logs)}ê°œì˜ ë¡œê·¸ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.**")
    col1, col2 = st.columns([1, 3])
    with col1:
        zip_data = download_manager.create_zip_archive(generated_logs)
        st.download_button(
            label="ğŸ“¦ ì „ì²´ ZIP ë‹¤ìš´ë¡œë“œ", data=zip_data,
            file_name=f"logs_archive_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
            mime="application/zip", use_container_width=True, type="primary"
        )
    st.divider()
    cols = st.columns(2)
    for idx, (log_type, log_data) in enumerate(generated_logs.items()):
        with cols[idx % 2]:
            with st.container():
                st.markdown(f"### {log_data['name']}")
                lines = log_data['content'].split('\n')
                st.write(f"ğŸ“„ **ë¼ì¸ ìˆ˜:** {len(lines):,}ê°œ")
                st.write(f"ğŸ“ **íŒŒì¼ í¬ê¸°:** {len(log_data['content'].encode('utf-8')):,} bytes")
                with st.expander("ğŸ‘€ ë¯¸ë¦¬ë³´ê¸°"):
                    preview_lines = lines[:10]
                    st.code('\n'.join(preview_lines), language='text')
                    if len(lines) > 10: st.write(f"... ({len(lines) - 10}ê°œ ë¼ì¸ ë”)")
                st.download_button(
                    label=f"ğŸ“¥ {log_data['filename']}", data=log_data['content'],
                    file_name=log_data['filename'], mime="text/plain", use_container_width=True
                )

if __name__ == "__main__":
    main()

